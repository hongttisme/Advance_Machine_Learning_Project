{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989ff23b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tan04\\AppData\\Local\\Temp\\ipykernel_20144\\1226082981.py:165: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=device)\n",
      "                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 7.5057, Test Loss: 6.6284, Test Policy Loss: 5.0311, Test Value Loss: 1.5973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "checkpoint [2]:  75%|███████▌  | 403/535 [08:42<02:52,  1.31s/it]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from graph_encode import move_to_index, encode_node_features, create_batch_from_boards\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "from our_model import ChessGNN\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "import chess\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class GraphChessDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataframe):\n",
    "        self.df = dataframe\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        moves_uci = row['Moves_UCI'].split()\n",
    "        result = row['Result']\n",
    "\n",
    "        if len(moves_uci) < 2:\n",
    "            return self.__getitem__(random.randint(0, len(self) - 1))\n",
    "\n",
    "        move_idx_to_play = random.randint(0, len(moves_uci) - 1)\n",
    "        board = chess.Board()\n",
    "\n",
    "        for move_uci in moves_uci[:move_idx_to_play]:\n",
    "            try:\n",
    "                board.push_uci(move_uci)\n",
    "            except chess.IllegalMoveError:\n",
    "                return self.__getitem__(random.randint(0, len(self) - 1))\n",
    "\n",
    "        target_move_uci = moves_uci[move_idx_to_play]\n",
    "        policy_target = uci_to_index(target_move_uci)\n",
    "        \n",
    "        if policy_target == -1:\n",
    "             return self.__getitem__(random.randint(0, len(self) - 1))\n",
    "\n",
    "        value_target = result_to_value(result)\n",
    "        if board.turn == chess.BLACK:\n",
    "            value_target = -value_target\n",
    "        \n",
    "        return board, policy_target, value_target\n",
    "\n",
    "def uci_to_index(uci_move):\n",
    "    try:\n",
    "        move = chess.Move.from_uci(uci_move)\n",
    "        return move_to_index[chess.Move(move.from_square, move.to_square)]\n",
    "    except:\n",
    "        print(\"error encode!!\", chess.Move.from_uci(uci_move)) \n",
    "        return -1\n",
    "\n",
    "def state_to_tensor(board: chess.Board):\n",
    "    tensor = encode_node_features(board)\n",
    "    return tensor.T.reshape((21, 8, 8))\n",
    "\n",
    "\n",
    "def result_to_value(result: str):\n",
    "    if result == '1-0': return 1.0\n",
    "    elif result == '0-1': return -1.0\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "\n",
    "def collate_graph_data(batch):\n",
    "\n",
    "    boards, policy_targets, value_targets = zip(*batch)\n",
    "\n",
    "    batched_graph_data = create_batch_from_boards(list(boards))\n",
    "\n",
    "    policy_targets = torch.tensor(policy_targets, dtype=torch.long)\n",
    "    value_targets = torch.tensor(value_targets, dtype=torch.float32).unsqueeze(1) \n",
    "\n",
    "    return batched_graph_data, policy_targets, value_targets\n",
    "\n",
    "# --- End of Placeholder Definitions ---\n",
    "\n",
    "\n",
    "def evaluate_and_plot(checkpoint_dir='checkpoints of our model2'):\n",
    "    \"\"\"\n",
    "    Loads trained models from checkpoints, evaluates them on the test set,\n",
    "    and plots the training and test losses.\n",
    "    \"\"\"\n",
    "    NODE_IN_FEATURES = 21\n",
    "    EDGE_IN_FEATURES = 11\n",
    "    GNN_NODE_OUT_FEATURES = 56\n",
    "    NUM_POSSIBLE_MOVES = 1792\n",
    "\n",
    "    BATCH_SIZE = 128\n",
    "    TEST_SIZE = 0.1\n",
    "    VAL_SIZE = 0.1\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Load and split the dataset\n",
    "    try:\n",
    "        full_df = pd.read_csv('kingbase_processed_all.csv')\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: 'kingbase_processed_all.csv' not found. Please ensure the dataset is in the correct directory.\")\n",
    "        # As a fallback for demonstration, create a dummy dataframe\n",
    "        data = {'fen': ['rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1'] * 1000}\n",
    "        full_df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "    train_val_df, test_df = train_test_split(full_df, test_size=TEST_SIZE, random_state=42)\n",
    "    \n",
    "    test_dataset = GraphChessDataset(dataframe=test_df)\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        collate_fn=collate_graph_data\n",
    "    )\n",
    "\n",
    "    model = ChessGNN(\n",
    "        node_in_features=NODE_IN_FEATURES,\n",
    "        edge_in_features=EDGE_IN_FEATURES,\n",
    "        gnn_hidden_features=GNN_NODE_OUT_FEATURES,\n",
    "        num_possible_moves=NUM_POSSIBLE_MOVES,\n",
    "    ).to(device)\n",
    "\n",
    "    policy_loss_fn = nn.CrossEntropyLoss()\n",
    "    value_loss_fn = nn.MSELoss()\n",
    "\n",
    "    if not os.path.exists(checkpoint_dir) or not os.listdir(checkpoint_dir):\n",
    "        print(f\"Checkpoint directory '{checkpoint_dir}' is empty or does not exist.\")\n",
    "        return\n",
    "\n",
    "    checkpoint_files = sorted(\n",
    "        [f for f in os.listdir(checkpoint_dir) if f.endswith('.pth')],\n",
    "        key=lambda x: int(x.split('_')[-1].split('.')[0])\n",
    "    )\n",
    "\n",
    "    if not checkpoint_files:\n",
    "        print(\"No checkpoint files found.\")\n",
    "        return\n",
    "\n",
    "    history = {\n",
    "        'epochs': [],\n",
    "        'train_loss': [],\n",
    "        'test_loss': [],\n",
    "        'train_policy_loss': [],\n",
    "        'test_policy_loss': [],\n",
    "        'train_value_loss': [],\n",
    "        'test_value_loss': []\n",
    "    }\n",
    "\n",
    "    a = 0\n",
    "\n",
    "    for checkpoint_file in checkpoint_files:\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, checkpoint_file)\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "        \n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        epoch = checkpoint['epoch']\n",
    "        history['epochs'].append(epoch)\n",
    "        history['train_loss'].append(checkpoint.get('loss')) # Use .get for backward compatibility\n",
    "\n",
    "        # To get separate policy and value losses, you would ideally save them during training.\n",
    "        # If not saved, we can't plot their history, but we can calculate them for the test set.\n",
    "        # For demonstration, we'll assume they are not in the checkpoint and will be calculated\n",
    "        # only for the test set at each checkpoint load.\n",
    "\n",
    "        # --- Evaluation on Test Set ---\n",
    "        model.eval()\n",
    "        total_test_loss = 0.0\n",
    "        total_policy_loss = 0.0\n",
    "        total_value_loss = 0.0\n",
    "        a += 1\n",
    "\n",
    "        with torch.no_grad():\n",
    "            progress_bar = tqdm(test_loader, desc=f\"checkpoint [{a}]\", leave=False)\n",
    "            for batched_graph_data, policy_targets, value_targets in progress_bar:\n",
    "                node_features = batched_graph_data[\"node_feature_matrix\"].to(device)\n",
    "                edge_features = batched_graph_data[\"edge_feature_matrix\"].to(device)\n",
    "                global_features = batched_graph_data['global_node_vector'].to(device)\n",
    "                edge_index = batched_graph_data[\"edge_index\"].to(device)\n",
    "                edge_map = batched_graph_data[\"edge_map\"].to(device)\n",
    "                policy_targets = policy_targets.to(device)\n",
    "                value_targets = value_targets.to(device).float()\n",
    "\n",
    "                current_batch_size = len(policy_targets)\n",
    "\n",
    "                policy_logits, value_pred = model(\n",
    "                    node_feature_matrix=node_features,\n",
    "                    edge_feature_matrix=edge_features,\n",
    "                    global_node_vector=global_features,\n",
    "                    edge_index=edge_index,\n",
    "                    edge_map=edge_map,\n",
    "                    batch_size=current_batch_size\n",
    "                )\n",
    "\n",
    "                loss_policy = policy_loss_fn(policy_logits, policy_targets)\n",
    "                loss_value = value_loss_fn(value_pred, value_targets)\n",
    "                combined_loss = loss_policy + loss_value\n",
    "                \n",
    "                total_test_loss += combined_loss.item()\n",
    "                total_policy_loss += loss_policy.item()\n",
    "                total_value_loss += loss_value.item()\n",
    "\n",
    "        avg_test_loss = total_test_loss / len(test_loader)\n",
    "        avg_policy_loss = total_policy_loss / len(test_loader)\n",
    "        avg_value_loss = total_value_loss / len(test_loader)\n",
    "        \n",
    "        history['test_loss'].append(avg_test_loss)\n",
    "        history['test_policy_loss'].append(avg_policy_loss)\n",
    "        history['test_value_loss'].append(avg_value_loss)\n",
    "        \n",
    "        print(f\"Epoch {epoch}: Train Loss: {checkpoint.get('loss'):.4f}, Test Loss: {avg_test_loss:.4f}, Test Policy Loss: {avg_policy_loss:.4f}, Test Value Loss: {avg_value_loss:.4f}\")\n",
    "\n",
    "    # --- Plotting ---\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(12, 18), sharex=True)\n",
    "    \n",
    "    # Plot Combined Loss\n",
    "    ax1.plot(history['epochs'], history['train_loss'], 'o-', label='Training Combined Loss')\n",
    "    ax1.plot(history['epochs'], history['test_loss'], 'o-', label='Test Combined Loss')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_title('Combined Training and Test Loss')\n",
    "    ax1.legend()\n",
    "    \n",
    "    # Plot Policy Loss\n",
    "    ax2.plot(history['epochs'], history['test_policy_loss'], 'o-', label='Test Policy Loss')\n",
    "    # If you save train policy loss in checkpoint, you can plot it here\n",
    "    # ax2.plot(history['epochs'], history['train_policy_loss'], 'o-', label='Train Policy Loss')\n",
    "    ax2.set_ylabel('Policy Loss (Cross-Entropy)')\n",
    "    ax2.set_title('Policy Loss')\n",
    "    ax2.legend()\n",
    "\n",
    "    # Plot Value Loss\n",
    "    ax3.plot(history['epochs'], history['test_value_loss'], 'o-', label='Test Value Loss')\n",
    "    # If you save train value loss in checkpoint, you can plot it here\n",
    "    # ax3.plot(history['epochs'], history['train_value_loss'], 'o-', label='Train Value Loss')\n",
    "    ax3.set_xlabel('Epochs')\n",
    "    ax3.set_ylabel('Value Loss (MSE)')\n",
    "    ax3.set_title('Value Loss')\n",
    "    ax3.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    evaluate_and_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a22e8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchGPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
