{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52754e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created 64 nodes\n",
      "created 1792 edge\n",
      "current state (FEN): r1bqkbnr/pppp1ppp/2n5/1B2p3/4P3/5N2/PPPP1PPP/RNBQK2R b KQkq - 3 3\n",
      "\n",
      "encode result:\n",
      "node matrix shape: (64, 12)\n",
      "edge matrix shape: (1792, 11)\n",
      "--- Static Graph Components ---\n",
      "static_edge_index shape: torch.Size([2, 1792])\n",
      "static_edge_map shape: torch.Size([1792])\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "from our_model2 import  ChessGNN\n",
    "\n",
    "from our_graph2_encode import move_to_index, encode_node_features, create_batch_from_boards\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38a551be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "import numpy as np\n",
    "import chess\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4786fad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uci_to_index(uci_move):\n",
    "    try:\n",
    "        move = chess.Move.from_uci(uci_move)\n",
    "        return move_to_index[chess.Move(move.from_square, move.to_square)]\n",
    "    except:\n",
    "        print(\"error encode!!\", chess.Move.from_uci(uci_move)) \n",
    "        return -1\n",
    "\n",
    "def state_to_tensor(board: chess.Board):\n",
    "    tensor = encode_node_features(board)\n",
    "    return tensor.T.reshape((21, 8, 8))\n",
    "\n",
    "\n",
    "def result_to_value(result: str):\n",
    "    if result == '1-0': return 1.0\n",
    "    elif result == '0-1': return -1.0\n",
    "    return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ec0f970",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphChessDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataframe):\n",
    "        self.df = dataframe\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        moves_uci = row['Moves_UCI'].split()\n",
    "        result = row['Result']\n",
    "\n",
    "        if len(moves_uci) < 2:\n",
    "            return self.__getitem__(random.randint(0, len(self) - 1))\n",
    "\n",
    "        move_idx_to_play = random.randint(0, len(moves_uci) - 1)\n",
    "        board = chess.Board()\n",
    "\n",
    "        for move_uci in moves_uci[:move_idx_to_play]:\n",
    "            try:\n",
    "                board.push_uci(move_uci)\n",
    "            except chess.IllegalMoveError:\n",
    "                return self.__getitem__(random.randint(0, len(self) - 1))\n",
    "\n",
    "        target_move_uci = moves_uci[move_idx_to_play]\n",
    "        policy_target = uci_to_index(target_move_uci)\n",
    "        \n",
    "        if policy_target == -1:\n",
    "             return self.__getitem__(random.randint(0, len(self) - 1))\n",
    "\n",
    "        value_target = result_to_value(result)\n",
    "        if board.turn == chess.BLACK:\n",
    "            value_target = -value_target\n",
    "        \n",
    "        return board, policy_target, value_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51fc2ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_graph_data(batch):\n",
    "\n",
    "    boards, policy_targets, value_targets = zip(*batch)\n",
    "\n",
    "    batched_graph_data = create_batch_from_boards(list(boards))\n",
    "\n",
    "    policy_targets = torch.tensor(policy_targets, dtype=torch.long)\n",
    "    value_targets = torch.tensor(value_targets, dtype=torch.float32).unsqueeze(1) \n",
    "\n",
    "    return batched_graph_data, policy_targets, value_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00ec8273",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return total_params, trainable_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383b9751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training script is defined. Uncomment 'train_chess_model()' to run.\n",
      "Using device: cuda\n",
      "No checkpoint found. Starting training from scratch.\n",
      "Starting training...\n",
      "Total parameters: 7,419,209\n",
      "Trainable parameters: 7,419,209\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Average Loss: 6.5794\n",
      "Checkpoint saved to checkpoints of our model2\\checkpoint_epoch_1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], Average Loss: 5.2407\n",
      "Checkpoint saved to checkpoints of our model2\\checkpoint_epoch_2.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], Average Loss: 4.8515\n",
      "Checkpoint saved to checkpoints of our model2\\checkpoint_epoch_3.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], Average Loss: 4.6214\n",
      "Checkpoint saved to checkpoints of our model2\\checkpoint_epoch_4.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 134\u001b[39m\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m'\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    133\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTraining script is defined. Uncomment \u001b[39m\u001b[33m'\u001b[39m\u001b[33mtrain_chess_model()\u001b[39m\u001b[33m'\u001b[39m\u001b[33m to run.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     \u001b[43mtrain_chess_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 95\u001b[39m, in \u001b[36mtrain_chess_model\u001b[39m\u001b[34m(checkpoint_dir)\u001b[39m\n\u001b[32m     91\u001b[39m current_batch_size = \u001b[38;5;28mlen\u001b[39m(policy_targets)\n\u001b[32m     93\u001b[39m optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m policy_logits, value_pred = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnode_feature_matrix\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnode_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[43m    \u001b[49m\u001b[43medge_feature_matrix\u001b[49m\u001b[43m=\u001b[49m\u001b[43medge_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[43m    \u001b[49m\u001b[43mglobal_node_vector\u001b[49m\u001b[43m=\u001b[49m\u001b[43mglobal_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[43m    \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[43m    \u001b[49m\u001b[43medge_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43medge_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcurrent_batch_size\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m loss_policy = policy_loss_fn(policy_logits, policy_targets)\n\u001b[32m    108\u001b[39m loss_value = value_loss_fn(value_pred, value_targets)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tan04\\anaconda3\\envs\\pytorchGPU\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tan04\\anaconda3\\envs\\pytorchGPU\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tan04\\Documents\\codeplace\\AI\\advance ML\\Advance_Machine_Learning_Project\\our_model2.py:248\u001b[39m, in \u001b[36mChessGNN.forward\u001b[39m\u001b[34m(self, node_feature_matrix, edge_feature_matrix, global_node_vector, edge_index, edge_map, batch_size)\u001b[39m\n\u001b[32m    245\u001b[39m expanded_global_node = current_global_node.unsqueeze(\u001b[32m1\u001b[39m).repeat(\u001b[32m1\u001b[39m, num_nodes_per_graph, \u001b[32m1\u001b[39m).view(batch_size * num_nodes_per_graph, -\u001b[32m1\u001b[39m)\n\u001b[32m    247\u001b[39m \u001b[38;5;66;03m# Pass features through the Transformer block\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m248\u001b[39m x, e = \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpanded_global_node\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[38;5;66;03m# Update the global node using the output of the current layer\u001b[39;00m\n\u001b[32m    251\u001b[39m updater = \u001b[38;5;28mself\u001b[39m.global_updaters[i]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tan04\\anaconda3\\envs\\pytorchGPU\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tan04\\anaconda3\\envs\\pytorchGPU\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tan04\\Documents\\codeplace\\AI\\advance ML\\Advance_Machine_Learning_Project\\our_model2.py:153\u001b[39m, in \u001b[36mGATEAUTransformerBlock.forward\u001b[39m\u001b[34m(self, node_feature_matrix, edge_feature_matrix, edge_index, edge_map, global_node_features)\u001b[39m\n\u001b[32m    150\u001b[39m residual = node_feature_matrix\n\u001b[32m    151\u001b[39m x_norm = \u001b[38;5;28mself\u001b[39m.norm1(node_feature_matrix)\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m attn_output, new_edge_features = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m    \u001b[49m\u001b[43mx_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_feature_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobal_node_features\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    157\u001b[39m x = residual + \u001b[38;5;28mself\u001b[39m.dropout1(attn_output)\n\u001b[32m    159\u001b[39m residual = x\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tan04\\anaconda3\\envs\\pytorchGPU\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tan04\\anaconda3\\envs\\pytorchGPU\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def train_chess_model(checkpoint_dir='checkpoints of our model2'):\n",
    "\n",
    "    NODE_IN_FEATURES = 12\n",
    "    EDGE_IN_FEATURES = 11\n",
    "    GNN_NODE_OUT_FEATURES = 56\n",
    "    GLOBAL_NODE_IN_FEATURES = 9\n",
    "    NUM_POSSIBLE_MOVES = 1792\n",
    "\n",
    "    EPOCHS = 20\n",
    "    BATCH_SIZE = 128\n",
    "    LEARNING_RATE = 0.001\n",
    "    TEST_SIZE = 0.1\n",
    "    VAL_SIZE = 0.1 \n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "\n",
    "    full_df = pd.read_csv('kingbase_processed_all.csv')\n",
    "    train_val_df, test_df = train_test_split(full_df, test_size=TEST_SIZE, random_state=42)\n",
    "    train_df, val_df = train_test_split(train_val_df, test_size=(VAL_SIZE / (1 - TEST_SIZE)), random_state=42)\n",
    "\n",
    "\n",
    "    dataset = GraphChessDataset(dataframe=train_df)\n",
    "    data_loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        collate_fn=collate_graph_data\n",
    "    )\n",
    "\n",
    "    model = ChessGNN(\n",
    "        node_in_features=NODE_IN_FEATURES,\n",
    "        edge_in_features=EDGE_IN_FEATURES,\n",
    "        global_node_in_features = GLOBAL_NODE_IN_FEATURES,\n",
    "        gnn_hidden_features=GNN_NODE_OUT_FEATURES,\n",
    "        num_possible_moves=NUM_POSSIBLE_MOVES,\n",
    "    ).to(device)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    policy_loss_fn = nn.CrossEntropyLoss()\n",
    "    value_loss_fn = nn.MSELoss()\n",
    "\n",
    "    start_epoch = 0\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    \n",
    "    latest_checkpoint_path = None\n",
    "    if os.listdir(checkpoint_dir):\n",
    "        checkpoint_files = [f for f in os.listdir(checkpoint_dir) if f.startswith('checkpoint_epoch_') and f.endswith('.pth')]\n",
    "        if checkpoint_files:\n",
    "            latest_epoch = max([int(f.split('_')[-1].split('.')[0]) for f in checkpoint_files])\n",
    "            latest_checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_epoch_{latest_epoch}.pth')\n",
    "\n",
    "    if latest_checkpoint_path:\n",
    "        print(f\"Resuming training from checkpoint: {latest_checkpoint_path}\")\n",
    "        checkpoint = torch.load(latest_checkpoint_path, map_location=device)\n",
    "        \n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        start_epoch = checkpoint['epoch']  \n",
    "        print(f\"Loaded model state from epoch {checkpoint['epoch']}. Starting from epoch {start_epoch + 1}.\")\n",
    "    else:\n",
    "        print(\"No checkpoint found. Starting training from scratch.\")\n",
    "\n",
    "\n",
    "    print(\"Starting training...\")\n",
    "    total, trainable = count_parameters(model)\n",
    "    print(f\"Total parameters: {total:,}\")\n",
    "    print(f\"Trainable parameters: {trainable:,}\\n\\n\")\n",
    "    for epoch in range(start_epoch, EPOCHS):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "\n",
    "        progress_bar = tqdm(data_loader, desc=f\"Epoch [{epoch+1}/{EPOCHS}]\", leave=False)\n",
    "        \n",
    "        for batched_graph_data, policy_targets, value_targets in progress_bar:\n",
    "            node_features = batched_graph_data[\"node_feature_matrix\"].to(device) # [B * 64, 12]\n",
    "            edge_features = batched_graph_data[\"edge_feature_matrix\"].to(device) # [B * 1792, 11]\n",
    "            global_features = batched_graph_data['global_node_vector'].to(device)# [B * 1, 9]\n",
    "            edge_index = batched_graph_data[\"edge_index\"].to(device)             # [B * 1792, 11]\n",
    "            edge_map = batched_graph_data[\"edge_map\"].to(device)                 # [1792]\n",
    "            policy_targets = policy_targets.to(device)                           # [B]\n",
    "            value_targets = value_targets.to(device).float()                     # [B , 1]\n",
    "\n",
    "\n",
    "            \n",
    "            current_batch_size = len(policy_targets)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            policy_logits, value_pred = model(\n",
    "                node_feature_matrix=node_features,\n",
    "                edge_feature_matrix=edge_features,\n",
    "                global_node_vector=global_features,\n",
    "                edge_index=edge_index,\n",
    "                edge_map=edge_map,\n",
    "                batch_size=current_batch_size\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            loss_policy = policy_loss_fn(policy_logits, policy_targets)\n",
    "            loss_value = value_loss_fn(value_pred, value_targets)\n",
    "            combined_loss = loss_policy + loss_value\n",
    "\n",
    "            combined_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += combined_loss.item()\n",
    "            progress_bar.set_postfix(loss=combined_loss.item())\n",
    "\n",
    "        avg_loss = total_loss / len(data_loader)\n",
    "        print(f\"Epoch [{epoch+1}/{EPOCHS}], Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_epoch_{epoch+1}.pth')\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': avg_loss,\n",
    "        }, checkpoint_path)\n",
    "        print(f\"Checkpoint saved to {checkpoint_path}\")\n",
    "\n",
    "\n",
    "    print(\"Training finished.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(\"Training script is defined. Uncomment 'train_chess_model()' to run.\")\n",
    "    train_chess_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667fe7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trained_model(checkpoint_path, device):\n",
    "\n",
    "    NODE_IN_FEATURES = 21   \n",
    "    EDGE_IN_FEATURES = 11   \n",
    "    GNN_NODE_OUT_FEATURES = 64 \n",
    "    NUM_POSSIBLE_MOVES = 1792 \n",
    "    \n",
    "    model = ChessGNN(\n",
    "        node_in_features=NODE_IN_FEATURES,\n",
    "        edge_in_features=EDGE_IN_FEATURES,\n",
    "        gnn_hidden_features=GNN_NODE_OUT_FEATURES,\n",
    "        num_possible_moves=NUM_POSSIBLE_MOVES\n",
    "    )\n",
    "    \n",
    "\n",
    "    try:\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Checkpoint file not found at {checkpoint_path}\")\n",
    "        return None\n",
    "        \n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    print(f\"Model loaded from {checkpoint_path} and is ready for inference.\")\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchGPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
