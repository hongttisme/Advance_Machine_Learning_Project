{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52754e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created 64 nodes\n",
      "created 1792 edge\n",
      "current state (FEN): r1bqkbnr/pppp1ppp/2n5/1B2p3/4P3/5N2/PPPP1PPP/RNBQK2R b KQkq - 3 3\n",
      "\n",
      "encode result:\n",
      "node matrix shape: (64, 21)\n",
      "edge matrix shape: (1792, 11)\n",
      "--- Static Graph Components ---\n",
      "static_edge_index shape: torch.Size([2, 1792])\n",
      "static_edge_map shape: torch.Size([1792])\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "from ResGATEAU_model import  ChessGNN\n",
    "from graph_encode import move_to_index,encode_node_features, create_batch_from_boards\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38a551be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "import numpy as np\n",
    "import chess\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4786fad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uci_to_index(uci_move):\n",
    "    try:\n",
    "        move = chess.Move.from_uci(uci_move)\n",
    "        return move_to_index[chess.Move(move.from_square, move.to_square)]\n",
    "    except:\n",
    "        print(\"error encode!!\", chess.Move.from_uci(uci_move)) \n",
    "        return -1\n",
    "\n",
    "def state_to_tensor(board: chess.Board):\n",
    "    tensor = encode_node_features(board)\n",
    "    return tensor.T.reshape((21, 8, 8))\n",
    "\n",
    "\n",
    "def result_to_value(result: str):\n",
    "    if result == '1-0': return 1.0\n",
    "    elif result == '0-1': return -1.0\n",
    "    return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ec0f970",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphChessDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataframe):\n",
    "        self.df = dataframe\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        moves_uci = row['Moves_UCI'].split()\n",
    "        result = row['Result']\n",
    "\n",
    "        if len(moves_uci) < 2:\n",
    "            return self.__getitem__(random.randint(0, len(self) - 1))\n",
    "\n",
    "        move_idx_to_play = random.randint(0, len(moves_uci) - 1)\n",
    "        board = chess.Board()\n",
    "\n",
    "        for move_uci in moves_uci[:move_idx_to_play]:\n",
    "            try:\n",
    "                board.push_uci(move_uci)\n",
    "            except chess.IllegalMoveError:\n",
    "                return self.__getitem__(random.randint(0, len(self) - 1))\n",
    "\n",
    "        target_move_uci = moves_uci[move_idx_to_play]\n",
    "        policy_target = uci_to_index(target_move_uci)\n",
    "        \n",
    "        if policy_target == -1:\n",
    "             return self.__getitem__(random.randint(0, len(self) - 1))\n",
    "\n",
    "        value_target = result_to_value(result)\n",
    "        if board.turn == chess.BLACK:\n",
    "            value_target = -value_target\n",
    "        \n",
    "        return board, policy_target, value_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51fc2ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_graph_data(batch):\n",
    "\n",
    "    boards, policy_targets, value_targets = zip(*batch)\n",
    "\n",
    "    batched_graph_data = create_batch_from_boards(list(boards))\n",
    "\n",
    "    policy_targets = torch.tensor(policy_targets, dtype=torch.long)\n",
    "    value_targets = torch.tensor(value_targets, dtype=torch.float32).unsqueeze(1) \n",
    "\n",
    "    return batched_graph_data, policy_targets, value_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00ec8273",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return total_params, trainable_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "383b9751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training script is defined. Uncomment 'train_chess_model()' to run.\n",
      "Using device: cuda\n",
      "No checkpoint found. Starting training from scratch.\n",
      "Starting training...\n",
      "Total parameters: 7,287,809\n",
      "Trainable parameters: 7,287,809\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 125\u001b[39m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m'\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTraining script is defined. Uncomment \u001b[39m\u001b[33m'\u001b[39m\u001b[33mtrain_chess_model()\u001b[39m\u001b[33m'\u001b[39m\u001b[33m to run.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[43mtrain_chess_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 78\u001b[39m, in \u001b[36mtrain_chess_model\u001b[39m\u001b[34m(checkpoint_dir)\u001b[39m\n\u001b[32m     74\u001b[39m total_loss = \u001b[32m0.0\u001b[39m\n\u001b[32m     76\u001b[39m progress_bar = tqdm(data_loader, desc=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEPOCHS\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m, leave=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatched_graph_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpolicy_targets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_targets\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnode_features\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatched_graph_data\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnode_feature_matrix\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[43m    \u001b[49m\u001b[43medge_features\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatched_graph_data\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43medge_feature_matrix\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tan04\\anaconda3\\envs\\pytorchGPU\\Lib\\site-packages\\tqdm\\std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tan04\\anaconda3\\envs\\pytorchGPU\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    698\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    699\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    700\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m701\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    703\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    704\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    705\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    706\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    707\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tan04\\anaconda3\\envs\\pytorchGPU\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    755\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    756\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m757\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    758\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    759\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tan04\\anaconda3\\envs\\pytorchGPU\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mGraphChessDataset.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     row = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     11\u001b[39m     moves_uci = row[\u001b[33m'\u001b[39m\u001b[33mMoves_UCI\u001b[39m\u001b[33m'\u001b[39m].split()\n\u001b[32m     12\u001b[39m     result = row[\u001b[33m'\u001b[39m\u001b[33mResult\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tan04\\anaconda3\\envs\\pytorchGPU\\Lib\\site-packages\\pandas\\core\\indexing.py:1191\u001b[39m, in \u001b[36m_LocationIndexer.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1189\u001b[39m maybe_callable = com.apply_if_callable(key, \u001b[38;5;28mself\u001b[39m.obj)\n\u001b[32m   1190\u001b[39m maybe_callable = \u001b[38;5;28mself\u001b[39m._check_deprecated_callable_usage(key, maybe_callable)\n\u001b[32m-> \u001b[39m\u001b[32m1191\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tan04\\anaconda3\\envs\\pytorchGPU\\Lib\\site-packages\\pandas\\core\\indexing.py:1754\u001b[39m, in \u001b[36m_iLocIndexer._getitem_axis\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1751\u001b[39m \u001b[38;5;66;03m# validate the location\u001b[39;00m\n\u001b[32m   1752\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_integer(key, axis)\n\u001b[32m-> \u001b[39m\u001b[32m1754\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_ixs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tan04\\anaconda3\\envs\\pytorchGPU\\Lib\\site-packages\\pandas\\core\\frame.py:4001\u001b[39m, in \u001b[36mDataFrame._ixs\u001b[39m\u001b[34m(self, i, axis)\u001b[39m\n\u001b[32m   3999\u001b[39m copy = \u001b[38;5;28misinstance\u001b[39m(new_mgr.array, np.ndarray) \u001b[38;5;129;01mand\u001b[39;00m new_mgr.array.base \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   4000\u001b[39m result = \u001b[38;5;28mself\u001b[39m._constructor_sliced_from_mgr(new_mgr, axes=new_mgr.axes)\n\u001b[32m-> \u001b[39m\u001b[32m4001\u001b[39m result._name = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m   4002\u001b[39m result = result.__finalize__(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m   4003\u001b[39m result._set_is_copy(\u001b[38;5;28mself\u001b[39m, copy=copy)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tan04\\anaconda3\\envs\\pytorchGPU\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5386\u001b[39m, in \u001b[36mIndex.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   5374\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   5375\u001b[39m \u001b[33;03mOverride numpy.ndarray's __getitem__ method to work as desired.\u001b[39;00m\n\u001b[32m   5376\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   5382\u001b[39m \n\u001b[32m   5383\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   5384\u001b[39m getitem = \u001b[38;5;28mself\u001b[39m._data.\u001b[34m__getitem__\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m5386\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mis_integer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m is_float(key):\n\u001b[32m   5387\u001b[39m     \u001b[38;5;66;03m# GH#44051 exclude bool, which would return a 2d ndarray\u001b[39;00m\n\u001b[32m   5388\u001b[39m     key = com.cast_scalar_indexer(key)\n\u001b[32m   5389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m getitem(key)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def train_chess_model(checkpoint_dir='checkpoints_testing'):\n",
    "\n",
    "    NODE_IN_FEATURES = 21\n",
    "    EDGE_IN_FEATURES = 11\n",
    "    GNN_NODE_OUT_FEATURES = 64\n",
    "    NUM_POSSIBLE_MOVES = 1792\n",
    "\n",
    "    EPOCHS = 40\n",
    "    BATCH_SIZE = 128\n",
    "    LEARNING_RATE = 0.001\n",
    "    TEST_SIZE = 0.1\n",
    "    VAL_SIZE = 0.1 \n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "\n",
    "    full_df = pd.read_csv('kingbase_processed_all.csv')\n",
    "    train_val_df, test_df = train_test_split(full_df, test_size=TEST_SIZE, random_state=42)\n",
    "    train_df, val_df = train_test_split(train_val_df, test_size=(VAL_SIZE / (1 - TEST_SIZE)), random_state=42)\n",
    "\n",
    "\n",
    "    dataset = GraphChessDataset(dataframe=train_df)\n",
    "    data_loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        collate_fn=collate_graph_data\n",
    "    )\n",
    "\n",
    "    model = ChessGNN(\n",
    "        node_in_features=NODE_IN_FEATURES,\n",
    "        edge_in_features=EDGE_IN_FEATURES,\n",
    "        gnn_hidden_features=GNN_NODE_OUT_FEATURES,\n",
    "        num_possible_moves=NUM_POSSIBLE_MOVES\n",
    "    ).to(device)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    policy_loss_fn = nn.CrossEntropyLoss()\n",
    "    value_loss_fn = nn.MSELoss()\n",
    "\n",
    "    start_epoch = 0\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    \n",
    "    latest_checkpoint_path = None\n",
    "    if os.listdir(checkpoint_dir):\n",
    "        checkpoint_files = [f for f in os.listdir(checkpoint_dir) if f.startswith('checkpoint_epoch_') and f.endswith('.pth')]\n",
    "        if checkpoint_files:\n",
    "            latest_epoch = max([int(f.split('_')[-1].split('.')[0]) for f in checkpoint_files])\n",
    "            latest_checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_epoch_{latest_epoch}.pth')\n",
    "\n",
    "    if latest_checkpoint_path:\n",
    "        print(f\"Resuming training from checkpoint: {latest_checkpoint_path}\")\n",
    "        checkpoint = torch.load(latest_checkpoint_path, map_location=device)\n",
    "        \n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        start_epoch = checkpoint['epoch'] \n",
    "        print(f\"Loaded model state from epoch {checkpoint['epoch']}. Starting from epoch {start_epoch + 1}.\")\n",
    "    else:\n",
    "        print(\"No checkpoint found. Starting training from scratch.\")\n",
    "\n",
    "\n",
    "    print(\"Starting training...\")\n",
    "    total, trainable = count_parameters(model)\n",
    "    print(f\"Total parameters: {total:,}\")\n",
    "    print(f\"Trainable parameters: {trainable:,}\\n\\n\")\n",
    "    for epoch in range(start_epoch, EPOCHS):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "\n",
    "        progress_bar = tqdm(data_loader, desc=f\"Epoch [{epoch+1}/{EPOCHS}]\", leave=False)\n",
    "        \n",
    "        for batched_graph_data, policy_targets, value_targets in progress_bar:\n",
    "            node_features = batched_graph_data[\"node_feature_matrix\"].to(device)\n",
    "            edge_features = batched_graph_data[\"edge_feature_matrix\"].to(device)\n",
    "            edge_index = batched_graph_data[\"edge_index\"].to(device)\n",
    "            edge_map = batched_graph_data[\"edge_map\"].to(device)\n",
    "            policy_targets = policy_targets.to(device)\n",
    "            value_targets = value_targets.to(device).float() \n",
    "            \n",
    "            current_batch_size = len(policy_targets)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            policy_logits, value_pred = model(\n",
    "                node_feature_matrix=node_features,\n",
    "                edge_feature_matrix=edge_features,\n",
    "                edge_index=edge_index,\n",
    "                edge_map=edge_map,\n",
    "                batch_size=current_batch_size\n",
    "            )\n",
    "\n",
    "            loss_policy = policy_loss_fn(policy_logits, policy_targets)\n",
    "            loss_value = value_loss_fn(value_pred, value_targets)\n",
    "            combined_loss = loss_policy + loss_value\n",
    "\n",
    "            combined_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += combined_loss.item()\n",
    "            progress_bar.set_postfix(loss=combined_loss.item())\n",
    "\n",
    "        avg_loss = total_loss / len(data_loader)\n",
    "        print(f\"Epoch [{epoch+1}/{EPOCHS}], Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_epoch_{epoch+1}.pth')\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': avg_loss,\n",
    "        }, checkpoint_path)\n",
    "        print(f\"Checkpoint saved to {checkpoint_path}\")\n",
    "\n",
    "\n",
    "    print(\"Training finished.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(\"Training script is defined. Uncomment 'train_chess_model()' to run.\")\n",
    "    train_chess_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667fe7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trained_model(checkpoint_path, device):\n",
    "\n",
    "    NODE_IN_FEATURES = 21   \n",
    "    EDGE_IN_FEATURES = 11   \n",
    "    GNN_NODE_OUT_FEATURES = 64 \n",
    "    NUM_POSSIBLE_MOVES = 1792 \n",
    "    \n",
    "    model = ChessGNN(\n",
    "        node_in_features=NODE_IN_FEATURES,\n",
    "        edge_in_features=EDGE_IN_FEATURES,\n",
    "        gnn_hidden_features=GNN_NODE_OUT_FEATURES,\n",
    "        num_possible_moves=NUM_POSSIBLE_MOVES\n",
    "    )\n",
    "    \n",
    "\n",
    "    try:\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Checkpoint file not found at {checkpoint_path}\")\n",
    "        return None\n",
    "        \n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    print(f\"Model loaded from {checkpoint_path} and is ready for inference.\")\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchGPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
